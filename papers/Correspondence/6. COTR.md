
# COTR : Correspondence Transformer for Matching Across Images

[paper link here](https://arxiv.org/pdf/2103.14167.pdf)

## Abstract

We propose a novel framework for finding correspondences in images based on a deep nueral network that, given two images
and a query point in one of them, find its correspondence in the other.

Importantly, in order to capture both local and global priors, and to let our model relate between image regions using
the most relevant among said priors, we realize our network using a `transformer.`

## Introduction

Traditionally, two fundamental research directions exist for this probelm.
* One is to extract `sets of sparse keypoints` from both images and match themm in order to minimize an alignment metric.
* The other is to interpret correspondence as a dense process, where `every pixel` in this first image maps to a pixel in the second image.

In this work, we preset a solution that bridges this divide,
a novel network architecture that can express both forms of prior knowledge - global and local - and learn them implicitly from data.
