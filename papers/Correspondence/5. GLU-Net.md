
# GLU-Net : Global-Local Universal Network for Dense Flow and Correspondences

[paper link here](https://arxiv.org/abs/1912.05524)

## Abstract

In this work, we propose a universal network architecture that is directly applicable to all
the aforementioned dense correspondence problems.

## Introduction

The general problem of estimating correspondences between pairs of images can be
divided into several different tasks.
* geometric matching
* optical flow
* semantic matching

In this work, we therefore set out to design a universal architecture that jointly addresses `all aforementioned tasks.`

One key architectural aspect shared by a variety of correspondence networks is the reliance
on correlation layers, `computing local similarities` between deep features extracted from
the two images.

There are two correlation methods below.
* **local correlations** : This is suitable for small displacements, they are unable to capture large viewpoints changes.
* **global correlations** : This is capable of handling long-range matches, but computationally `unfeasible at high resolutions.`
Also, they constrain the input image size to a `predetermined resolution`, which severely hampers accuracy for high-resolution
images.

The main contributions of this work are below.
* introducing `single unified architecture`, applicable to geomoetric matching, semantic matching, and optical flow.
* Our network carefully `integrates global and local correlation layers` to handle both large and small distribution.
* To circumvent the fixed input resolution imposed by the global cost volume, we propose an `adaptive resolution strategy`
that enables our network to take any images resolution as input, crucial for high-accuracy displacements.
* We train our network in a `self-supervised manner`, relying on synthetic wraps of real images, thus requiring
`no annotated ground-truth flow.`

## Method

Our goal is to estimate a dense displacement field, often referred to as flow, *W* ∈ *R*<sup>H * W * 2</sup> that
wraps image *I*<sub>s</sub> towards *I*<sub>t</sub> such that,

> *I*<sub>t</sub> ≈ *I*<sub>s</sub>(*X* + *W*(*X*))

The flow *W* represents the `pixel-wise 2D motion vectors` in the target image coordinate system.
It is directly related to the pixel correspondence map *M*(*X*) = *X* + *W(*X*)*, which directly maps
an image coordinate *X* in the target image to its `corresponding position in the source image.`

In this work, we disign an architecture capable of robustly finding both long-range correspondences and
accurate estimation of pixel wise displacements.

### 3.1 Local and Global Correlations

The correlation can be performed in a local or global manner.

**Local correlation** : In a local correlation layer, the feature similarity is only evaluated
`in the neighborhood of the target image coordinate`, specified by a search radius *R*.

Formally, the correlation *c*<sup>l</sup> between the target *F*<sup>l</sup><sub>t</sub> ∈ 
R<sup>H<sup>l</sup> * W<sup>l</sup> * d<sup>l</sup> </sup> and source
*F*<sup>l</sup><sub>s</sub> ∈ R<sup>H<sup>l</sup> * W<sup>l</sup> * d<sup>l</sup> </sup> feature maps is
defined as,

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_5_2.png" width=500>

where *X* ∈ *Z*<sup>2</sup> is a coordinate in the target feature map and *d* ∈ *Z*<sup>2</sup> is the displacement
from this location.

The resulting 3D correlation volume *c*<sup>l</sup> thus has a dimensionality of H<sub>l</sub> * W<sub>l</sub> * (2R + 1)<sup>2</sup>

**Global correlation** : A global correlation layer evaluates the pairwise similarities between all locations in the
target and source feature maps.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_5_3.png" width=500>


