
# GLU-Net : Global-Local Universal Network for Dense Flow and Correspondences

[paper link here](https://arxiv.org/abs/1912.05524)

## Abstract

In this work, we propose a universal network architecture that is directly applicable to all
the aforementioned dense correspondence problems.

## Introduction

The general problem of estimating correspondences between pairs of images can be
divided into several different tasks.
* geometric matching
* optical flow
* semantic matching

In this work, we therefore set out to design a universal architecture that jointly addresses `all aforementioned tasks.`

One key architectural aspect shared by a variety of correspondence networks is the reliance
on correlation layers, `computing local similarities` between deep features extracted from
the two images.

There are two correlation methods below.
* **local correlations** : This is suitable for small displacements, they are unable to capture large viewpoints changes.
* **global correlations** : This is capable of handling long-range matches, but computationally `unfeasible at high resolutions.`
Also, they constrain the input image size to a `predetermined resolution`, which severely hampers accuracy for high-resolution
images.

The main contributions of this work are below.
* introducing `single unified architecture`, applicable to geomoetric matching, semantic matching, and optical flow.
* Our network carefully `integrates global and local correlation layers` to handle both large and small distribution.
* To circumvent the fixed input resolution imposed by the global cost volume, we propose an `adaptive resolution strategy`
that enables our network to take any images resolution as input, crucial for high-accuracy displacements.
* We train our network in a `self-supervised manner`, relying on synthetic wraps of real images, thus requiring
`no annotated ground-truth flow.`

## Method

Our goal is to estimate a dense displacement field, often referred to as flow, *W* ∈ *R*<sup>H * W * 2</sup> that
wraps image *I*<sub>s</sub> towards *I*<sub>t</sub> such that,

> *I*<sub>t</sub> ≈ *I*<sub>s</sub>(*X* + *W*(*X*))

The flow *W* represents the `pixel-wise 2D motion vectors` in the target image coordinate system.
It is directly related to the pixel correspondence map *M*(*X*) = *X* + *W(*X*)*, which directly maps
an image coordinate *X* in the target image to its `corresponding position in the source image.`

In this work, we disign an architecture capable of robustly finding both long-range correspondences and
accurate estimation of pixel wise displacements.

### 3.1 Local and Global Correlations

The correlation can be performed in a local or global manner.

**Local correlation** : In a local correlation layer, the feature similarity is only evaluated
`in the neighborhood of the target image coordinate`, specified by a search radius *R*.

Formally, the correlation *c*<sup>l</sup> between the target *F*<sup>l</sup><sub>t</sub> ∈ 
R<sup>H<sup>l</sup> * W<sup>l</sup> * d<sup>l</sup> </sup> and source
*F*<sup>l</sup><sub>s</sub> ∈ R<sup>H<sup>l</sup> * W<sup>l</sup> * d<sup>l</sup> </sup> feature maps is
defined as,

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_5_2.png" width=500>

where *X* ∈ *Z*<sup>2</sup> is a coordinate in the target feature map and *d* ∈ *Z*<sup>2</sup> is the displacement
from this location.

The resulting 3D correlation volume *c*<sup>l</sup> thus has a dimensionality of H<sub>l</sub> * W<sub>l</sub> * (2R + 1)<sup>2</sup>

**Global correlation** : A global correlation layer evaluates the pairwise similarities between all locations in the
target and source feature maps.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_5_3.png" width=300>

We vectorize the source dimensions, leading to a 3D tensor of size H<sub>l</sub> * W<sub>l</sub> * (H<sub>l</sub>W<sub>l</sub>).

**Comparison** : Local correlation layers can be applied for high-resolution feature maps, which allows `accurate estimation
of small displacements.` On the other hand, a local correlation based architecture is limited to a `certain maximum range of
displacements.` Conversely, a global correlation based architecture does not suffer from this limitation, but it is only
suitable at `coarse resolutions` due to computational problems.

### 3.2 Global - Local Architecture

We introduce a unified network that leverages the advantages of both global and local correlation layers and which also
circumvents the limitations of both.

Inspired by DGC-Net, we employ a global correlation layer at the coarsest level. In subsequent layers, the
dense flow field is refined by computing image feature similarity using local correlations.

### 3.3 Adaptive resolution

Our adaptive resolution architecture consists of two sub-networks, which operate on two different image resolutions.
* The first, termed L-Net, takes source and target images `downscaled` to a fixed resolution *H*<sub>l</sub> * *W*<sub>l</sub>,
which allows a global correlation layer to be integrated. It can handle very large displacements.
* The H-Net on the other hand, operates directly on the `orginal image resolution` *H* * *W*, which is not constrained to any
specific value.

For high-resolution images, `the upscaling factor` between finest pyramid level, *l*<sub>L</sub>, of L-Net and the coarsest,
*l*<sub>H</sub>, of H-Net can be significant.

The entire network is trained end-to-end.

### 3.4 Architecture details

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_5_4.png" width=800>

Our final architecture GLU-Net, composed of four pyramid levels in total, is detailed in Figure 3.

#### Coarsest resolution and mapping estimation

* computing a global correlation from the *L*<sup>2</sup>-normalized source and target features.
* cost volume is further post processed by applying channel-wise *L*<sup>2</sup>-normalized followed by ReLU to strongly
down-weight ambiguous matches.
* (like DGC-Net) resulting global correlation *C* is then fed into a correspondence map decoder *M*<sub>top</sub> to estimate
a 2D dense correspondence map *m*.
