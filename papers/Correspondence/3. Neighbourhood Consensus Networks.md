# Neighbourhood Consensus Networks

[paper link here](http://papers.neurips.cc/paper/7437-neighbourhood-consensus-networks.pdf)

[video](https://www.youtube.com/watch?v=sRBviaVN4GE)

## Abstract

We address the problem of finding `reliable dense correspondence` between a pair of images.
This is a challenging task due to `strong appearance differences between the corressponding scene
elements` and `ambiguities generated by repetitive patterns.`

The contributions of this work are threefold.

* We develop an `end-to-end trainable convolutional neural network architecture` that identifies sets of spatially
consistent matches by `analyzing neighbourhood consensus patterns` in the 4D space of all possible corresspondences
between a pair of images.
* We demonstrate that the model `can be trained effectively from weak supervision` in the form of mathcing and
non-matching image pairs without the need for costly manual annotation of point to point correspondences.
* We show the proposed neighbourhood consensus network `can be applied to a range of matching tasks including
both category and instance level matching.`

## Introduction

While we have now better local patch descriptors, the matching is still performed by variants of the nearest
neighbour assignment in a feature space followed by separate disambiguation stages based on geometric constaints.

However, this approach has fundamental limitaiton that cannot distinguish `repetitive patterns or textureless
regions.`

In this work, we take a different direction and develope a trainable neural network architecture that disambiguates
such challenging situations `by analyzing local neighbourhood patterns` in a full set of dense corresspondences.

The intuition is following : in order to disambiguate a match on a repetitive pattern, it is necessary
to `analyze a larger context of the scene that contains a unique non-repetitive feature.`
The information from this unique match can then be propagated to the neighbouring uncertain matches.

This powerful idea is typically known as `neighbourhood consensus` or more broadly as `semi-local constraints`.

In this work, we go one step further and propose a way of `learning neighbourhood consensus constraints directly`
from training data.

## Proposed approach

We design a model which learns to `discriminate a reliable match` by recognizing patterns of supporting
matches in its neighbourhood. Furthermore, We do this in a `fully differentiable way`, such that
this trainable matching module can be directly combined with strong CNN image descriptors.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_1.png" width=700>

There are five main components.
* dense feature extraction and matching
* the neighbourhood consensus network
* a soft mutual nearest neighbour filtering
* extraction of corresspondences from the output 4D filtered match tensor
* weakly supervised training loss

### 3.1 Dense feature extraction and matching

In order to produce an end-to-end trainable model, we follow the common practice of using
a deep convolutional neural network (CNN) as a dense feature extraction.

This convolutional network produce 2 feature extractions which is called *f*<sup>A</sup>, *f*<sup>B</sup>
for each pair of images.

And then, all pairwise feature matches need to be computed and stored. The correlation map c<sup>h * w * h * w</sup>
is produced for output.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_2.png" width=300>

> While classic hand-crafted neighbourhood consensus approaches are applied after a hard assignment
> of matches is done, this is `not well suited for developing a matching method that is differentiable`
> and amenable for end-to-end training. In addition, in case of repetitive features, assigning the match
> to the first nearset neighbour might result in an incorrect match.

### 3.2 Neighbourhood consensus network

Determining the correct matches from the correlation map is a significant challenge.
Note that the number of correct matches are of order of *hw*, while the size of the correlation map
is of the order of (*hw*)<sup>2</sup>. This means that the great majority of the information in
the correlation map `corresponds to matching noise` due to incorrectly matched features.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_3.png" width=700>

> we can expect correct matches to have a coherent set of supporting matches surrounding them in the 4-D space.
> These geometric patterns are equivariant with translations in the input images; that is, if the images are
> translated, the matching pattern is also translated in the 4-D space by an equal amount. This property motivates
> to use 4-D convolutions.

By processing 4D convolutional network, we establish a `strong locally prior on the relationships between matches.`
The aim is that these layers capture more complex patterns by combining the outputs from the previous layer.

Finally, in order to produce a method that is `invariant to the particular order of the input images`, that is,
that it will produce the same matches regardless of whether an image pair is input to the net as
(*I*<sup>A</sup>, *I*<sup>B</sup>) or (*I*<sup>B</sup>, *I*<sup>A</sup>), we propose to apply the network twice
in the following way.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_4.png" width=300>

This final output constitutes the *filtered matches c* using the neighbourhood consensus network, where matches
with inconsistent local patterns are `downweighted or removed.`

### 3.3 Soft mutual nearest neighbour filtering

Although, the proposed neighbourhood consensus network can suppress and amplify matches based on the
supporting evidence in their neighbourhoods, it cannot enforce global constraints on matches,
such as `reciprocal match, where matched features are required to be mutual nearest neighbours.`

We propose a softer version of the mutual nearest neighbour filtering, both in the sense of
`softer decision` and `better differentiability properties.`

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_5.png" width=800>

This soft mutual nearest netighbour filering operates as a gating mechanism on the input, downweighting the socres
of matches that are not mutual nearest neighbours.

While this filtering step `has no trainable parameters`, it can be inserted in the CNN pipeline at both training and
evaluation stages.

### 3.4 Extracting correspondences from the correlation map

Suppose that we want to match two images *I*<sup>A</sup> and *I*<sup>B</sup>. Then, the output of our model will
produce a 4-D filtered correlation map *c*, which contains scorse for all pairwise matches.

However for various applications, it is desirable to obtain a set of point-to-point image correspondences between
the two images.

For this purpose, two scores are defined from the correlation map, by performing soft-max in the dimensions correponding
to images A and B:

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_3_6.png" width=600>

Note that the scores are `positive`, `normalized` using the soft-max function.

Hence, we can interpret them as discrete conditional probability distributions of *f*<sub>*ij*</sub><sup>*A*</sup>,
*f*<sub>*ij*</sub><sup>*B*</sup> being a match, given the position (*i, j*) of the match in *A* or (*k, l*) in *B*.

<img src="" width=>

This probabilistic intution allows us to `model the match uncertainty using a probability distribution` and will be also
`useful to motivate the loss used for weakly supervised training`, which will be discribed next.

### 3.5 Weakly-supervised learning

