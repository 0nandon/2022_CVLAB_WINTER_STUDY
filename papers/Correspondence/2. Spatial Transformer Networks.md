
# Spatial Transformer Networks

[paper link here](https://arxiv.org/pdf/1506.02025.pdf)

[Tutorial code here](https://tutorials.pytorch.kr/intermediate/spatial_transformer_tutorial.html)

## Abstract

CNN define an exceptionally powerful class of models but are still limited by the lack of ability to be
`spatially invariant` to the input data in a computationally and parameter efficient manner.

In this work, we introduce a new learnable module, the `Spatial Transformer`, which `explicitly allows the
spatial manipulation of data` within the network.

This differentiable module can be inserted into existing convolutional architectures, giving neural
networks the ability to actively transform feature maps, conditional on the feature map itself,
`without any extra training supervision or modification to the optimisation process.`

## Introduction

A desirable property of a system which is able to reason about images is to `disentangle object pose` and `part deformation
from texture and shape.` The introduction of `local max-pooling layers` in CNNs has helped to satisfy this property.

However, due to the typically small spatial support for max-pooling this `spatial invariance is only realised over
a deep hierarchy of max-pooling and convolutions`, and the intermediate feature maps in a CNN `are not actually invariant
to large transformations of the input data.`

In this work, we introduce a `Spatial Transformer` module, that can be included into a standard neural network architecture
to provide spatial transformation capabilities.

Unlike pooling layers, `where the receptive fields are fixed and local`, the spatial transformer module is a dynamic mechanism
that `can actively spatially transform an image.`

**This can select not only regions of an image that are most relevant, but also to transform those regions to
a cannonical, expected pose to simplify recognition in the following layers.**

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_2_1.png" width=700>

THis spatial transformer can be worked as attention, a key benefit of using attention is that transformed, lower resolution
inputs can be used in favour of higher resolution raw inputs, resulting in increased computational efficiency.
