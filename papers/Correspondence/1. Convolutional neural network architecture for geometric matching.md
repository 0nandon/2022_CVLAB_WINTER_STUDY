# Convolutional neural network architecture for geometric matching

[paper link here](https://openaccess.thecvf.com/content_cvpr_2017/papers/Rocco_Convolutional_Neural_Network_CVPR_2017_paper.pdf)

## Abstract

The contributions of this work are three-fold.

* First, we propose a CNN work architecture for geometric matching. The architecture
is based on three main components that `mimic the standard steps of feature extraction, matching,
and simultaneous in-lier detection and model parameter estimation,` while being trainbale end-to-end.
* Second, network parameters can be trained from synthetically generated imagery `without the need for manual
annotation` and that our matching layer significantly increases generalization capabilities to never seen before images.
* Finally, we show that the same model can perform both instancfe-level and category-level matching giving SOTA results.

## Introduction

The traditional approach for estimating correspondences between images works well in many cases but fails
in situation that `exhibit large changes of depicted appearance` due to intra-class variation, or `large changes of
scene layout or non-rigid deformations` that require complex geometric models with many parameters.

In this work, we develop a CNN architecture that mimics the standard matching process.

First, we replce the standard local featuers with `powerful trainable CNN features`, which allows us
to handle large changes of appearance between the matched images.

Second, we develop `trainable matching and transformation estimation layers` that can cope with noisy and
incorrect matches in a robust way, mimicking the good practices in feature matching.

It can hendle `large appearance changes` and is therefore suitable for `both instance-level and category-level matching
problems.`

## Architecture for geometric matching

The architecture is designed to mimic the classical computer vision pipeline, while using `differentiable modules` so that
it is trainable end-to-end for the geometry estimation task.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_1.png" width=500>

There are 3 processes in this architecture.
* passing input images *I*<sub>A</sub>, *I*<sub>B</sub> through a siamese architecture consisting of CNN, thus extracting
feature maps *f*<sub>A</sub>, *f*<sub>B</sub> which are analogous to dense local descriptors.
* matching the feature maps : `global correlation`
* regresion network which directly outputs the parameters θ, of the geometric model in a robust manner.

### 3.1 Feature extraction

The first stage of the pipeline is feature extraction, for which we use a standard CNN architecture.

A CNN without fully connected layers takes an input image and produces a feature map *f* ∈ R<sup>h * w * d</sup>.

We use the VGG-16 network. As shown in Fig 2, the feature extraction network is duplicated and arranged in a siamese
configuration such that `the two input images are passed two identical networks which share parameters.`

### 3.2 Matching network

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_2.png" width=500>

Analogously to the classical approach, only descriptor similarities and their spatial locations should be
considered for geometry estimation.

To achieve this, we propose to use a correlation layer followed by normalization.

There are two steps.
* `all pairs of similarities` between descriptors are computed in the correlation layer.
* similarity scores are processed and normalized such that `ambiguous matches are strongly down-weighted.`

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_3.png" width=500>

It is important to postprocess the pairwise similarity scores to `remove ambiguous matches.`

The normalization is performed by ReLU, to zero out negative correlations, followed by L2-normalization.
This has two desirable effects.

* If descriptor *f*<sub>B</sub> correlates well with only a single feature in *f*<sub>A</sub>, the normalization will
amplify the score of the match.
* If descriptor *f*<sub>B</sub> matches multiple features in *f*<sub>A</sub> due to the existence of clutter or repetitive patterns,
matching scores will be down weighted.

#### Discussion

Previous works have used other matching layers to combine descriptors across images, `namely simple concatenation` of descriptors
along the channel dimension or `subtraction.`

But there are 2 problems in these methods.
* they are `unable to detect long-range matches`
* image content information is `directly outputted.`

We show that the concatenation and subtraction methods indeed have `difficulties generalizing beyond the
training set`, while our correlation layer achieves generalization yielding superior results.

### 3.3 Regression network

The normalized correlation map is passed through a regression network which `directly estimates parameters
of the geometric transformation` relating the two input images.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_4.png" width=500>

We gain mimic the classical approach using a neural network, where we stack `two blocks of CNN`, followed by
`batch normalization` and the `ReLU non-linearity` and `add a final fully connected layer` which r`egresses to the
parameters of the transformation.`

#### Discussion

A Potential alternative to a CNN regression network is `FC layers`. However, as the input correlaiton map size is quadratic in the
number of image features, `such a network would be hard to train due to a large number of parameters` that would need to be learned.

It should be noted that even though the layers in our architecture are convoulutional, the regressor `can learn to estimate large transformations.`

### 3.4. Hierarchy of transformations

Another commonly used approach when estimating image to image transformations is to start by `estimating a simple transformation` and
then `progressively increase` the model complexity.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_5.png" width=800>

> The motivation behind this method is that `estimating a very complex transformation could be hard` and computationally inefficient
> in the presence of clutter.

So, robust and fast rough estimation of a simpler transformation can be used `as starting point`, also regularizing the subsequent estimation
of the `more complex transformation.`

## Training

In order to train the parameters of our geometric matching CNN, it is necessary to design the appropriate loss function,
and to use suitable training data.

### 4.1 Loss function

We assume a fully supervised setting, where the raining data consists of pair of images and the desired outputs in the form
of the parameters θ with the ground truth transformation θ<sub>GT</sub>.

Namely, we construct a `grid points in image A`, transform it usnig the ground truth and neural network estimated
transformations T<sub>θ<sub>GT</sub></sub> and T<sub>θ</sub> with parameters θ<sub>GT</sub> and θ.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/correspondence_1_6.png" width=500>

The gradient of the loss function with respect to the transformation parameters, `needed to perform backpropagation
in order to learn network weights.`

### 4.2 Training from synthetic transformations

Training CNNs usually requires a lot of data, and `no public datasets exist` that contain many image pairs annotated with
their geometric transformation.

Therefore, we opt for training from `synthetically generated data`, which gives us the flexibility to gather
as many training examples as needed, for any 2-D geometric transformation of interest.

## Conclusions

We have described a network architecture for geometric matching `fully trainable` from synthetic imagery `without
the need for manual annotaitons`, resulting SOTA performance.
