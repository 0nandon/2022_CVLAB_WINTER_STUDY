
# PDC-Net + : Enhanced Probabilisitc Dense Correspondence Network

[paper link here](https://arxiv.org/pdf/2109.13912.pdf)

## Abstract

We propose PDC-Net+, capable of estimating accurate dense correspondences along with a reliable confidence map.
We develop a flexible probabilistic approach that jointly learns the `flow prediction and its uncertainty.`

* We parametrze the predictive distribution as a constrained mixture model, ensuring better modelling of
both accurate flow predictions and outliers.
* We develop an architecture and an enhanced training strategy tailored for `robust and generalizable uncertainty
prediction` in the context of self-supervised training.

# Introduction

For geometric matching applications, it is thus crucial to know `when and where to trust the estimated correspondences.`
The identification of inaccurate or incorrect matches is particularly important in, for instance,
dense 3D reconstruction, high quality image alignment, and multi-frame image restoration.

Moreover, dense confidence estimation `bridges the gap between the application domains of the dense and
sparse correspondence estimation paradigms.`

> It enables the selection of robust and accurate matches from the dense output, to be utilized in
> pose estimation and image-based localization.

**We propose the PDC-Net+, for joint learning of dense flow estimation along with its uncertainties.**

Our model learns to predict the `conditional probability density` of the dense flow between two images.

## Our Approach

We introduce PDC-Net+, a method for estimating the dense flow field relating two images, coupled with a
robust pixel-wise confidence map.

### 3.1 Probabilistic Flow Regression

Instead of generating a single flow prediction *Y*, out goal is to learn the conditional probability
density , of a flow *Y* given the input image pair *X* = (*I<sup>q</sup>*, *I<sup>r</sup>*).

This is generally achieved by leting a network predict the parameters ø(*X*;θ) of a family of distributions
*p*(*Y*|*X*;θ) = *p*(*Y*|ø(*X*;θ)).

Compared to the direct approach *Y* = *F(X;θ)*, the generated parameters ø(*X*;θ) of the predictive
distribution can encode `more information about the flow prediction, including its uncertainty.`

The predictive density is modeled using Gaussian or Laplace distributions.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/PDCNET_1.png" width=500>

### 3.2 Constrained Mixture Model Prediction

Current probabilistic methods mostly rely on a Laplacian model. A single Laplace can only predict an
intermediate variance, which does not faithfully represent `the more complicated uncertainty pattern
in this case.`

#### Mixture model

To achieve a flexible model capable of fitting more comlex distributions, we parametrize *p*(*Y*|*X*;θ)
with a mixture model. In general, we consider a distribution consisting of *M* components.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/PDCNET_2.png" width=300>







