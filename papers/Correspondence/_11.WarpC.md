
# Warp Consistency for Unsupervised Learning of Dense Correspondences

[paper link here](https://arxiv.org/pdf/2104.03308.pdf)

## Abstract

The key challenge in learning dense correspondences lies in the `lack of ground-truth matches` for real image pairs.

We propose WarpC, an unsupervised learning objective for dense correspondence regression.
Our objective is effective even in settings with large appearance and view-point changes.

From our observations and empiricalresults, we disign a `general unsupervised objective` employing two of the derived constraints.

## Introduction

While supervised deep learning methods have achieved impressive resutls, they are limited by the availability of ground truth annotations.
In fact, collecting denes ground-truth correspondence data of real scenes is estremely challenging and costly, if not possible.

We introduce Warp Consistency, an `unsupervised learning objective for dense correspondence regression.` Unlike previous approaches, it is
capable of handling large appearance and view-point changes, while also generalizing to unseen real data.

From a real image pair (*I*, *J*), we construct a third image *I*<sup>'</sup> by warping *I* with a known flow field *W*, that is
created by `randomly sampling homographies`, from a specified distribution. We then consider the `consistency graph` arising from
the resulting image triplet (*I*, *I*<sup>'</sup>, *J*). By carefully anlyzing their properties, we propose an unsupervised loss
based on predicting the flow W by the composiiton *I*sup>'</sup> > *J* > *I* via image *J*.

We perform comprehensibe empirical analysis of the objectives derived from our warp consistency grapn and compare them to existing
unsupervised alternatives.

## Method

### 3.1 Problem formulation and notation

We denote flow field to *F*<sub>*I > J*</sub> ∈ R<sup>h * w * 2</sup>, and it is directly related to the mapping *M*<sub>*I > J*</sub>
∈ R<sup>h * w * 2</sup>, which encodes the absolute location in *J* corresponding to the pixel location in image *I*.

It is thus related to the flow through *M*<sub>*I > J*</sub>(*x*) = *x* + *F*<sub>*I > J*</sub>.

Also, We define the warping ø<sub>*F*</sub>(*T*) of a functino *T* : R<sup>2</sup> > R<sup>d</sup> by the flow
*F* as ø<sub>*F*</sub>(*T*)(*x*) = *T*(*x* + *F*(*x*)). This is more compactly expressed as ø<sub>*F*</sub>(*T*) = *T* • *M*<sub>*F*</sub>,
where • denotes function composition.

The goal of this work is to learn a neural network *f*<sub>θ</sub>, with parameters θ, that predicts an estimated flow *F*<sup>^</sup><sub>*I > J*</sub>
= *f*<sub>θ</sub>(*I, J*) relating *I* to *J*.

> We will consistently use the hat ^ to denote an estimated or predicted quantity.

### 3.2 Unsupervised data losses

<img src="" width="">

To develop our approach, we first briefly review relavant existing alternatives for unsupervised learning of flow.

> We call a learning formulation 'unsupervised' if it does `not require any information` other than pairs of images (*I, J*) depicting
> the same scene of object. Specifically, unsupervised methods do not require `any annotations made by the humans` or other matching algortithms.

* Photometric losses
* Forward-backward consistency : It is enforced by the trivial degenerate solution of always predicting zero flow *F*<sup>^</sup><sub>I > J</sub> = 
*F*<sup>^</sup><sub>J > I</sub> = 0
* Warp-supervision

### 3.3 Warp consistency graph

### 3.6 Sampling warps W

During training, we `randomly sample` it from a distribution *W* ~ *p*w, which we need to design.

As discussed in previous section, the W-bipath loss approaches the forward-backward consistency loss when `the magnitude
of the warps decreases` ||*W*|| > 0. Exclusively sampling too small warps *W* ≈ 0 therefore risks `biasing the prediction towards zero.`

On the other hand, too large warps would render estimation of *F*<sup>^</sup><sub>I' > J</sub> challenging and introduce unnecessary
invalid image regions.

As as rough guide, the distribution *pw* should yield warps of `similar magnitued as the real transformations` ||*F*<sub>*J > I*</sub>||,
thus giving similar impact to all three terms in our loss function.

## Couclusion

We propose an unsupervised learning objective for dense correspondences, paritculary suitable for scenarios with `large changes
in appearance and geometry.` When integrated into three recent dense correspondence networks, our approach outperforms SOTA for
`multiple geometric and semantic mathcing datasets.`












