
# Warp Consistency for Unsupervised Learning of Dense Correspondences

[paper link here](https://arxiv.org/pdf/2104.03308.pdf)

## Abstract

The key challenge in learning dense correspondences lies in the `lack of ground-truth matches` for real image pairs.

We propose WarpC, an unsupervised learning objective for dense correspondence regression.
Our objective is effective even in settings with large appearance and view-point changes.

From our observations and empiricalresults, we disign a `general unsupervised objective` employing two of the derived constraints.

## Introduction

While supervised deep learning methods have achieved impressive resutls, they are limited by the availability of ground truth annotations.
In fact, collecting denes ground-truth correspondence data of real scenes is estremely challenging and costly, if not possible.

We introduce Warp Consistency, an `unsupervised learning objective for dense correspondence regression.` Unlike previous approaches, it is
capable of handling large appearance and view-point changes, while also generalizing to unseen real data.

From a real image pair (*I*, *J*), we construct a third image *I*<sup>'</sup> by warping *I* with a known flow field *W*, that is
created by `randomly sampling homographies`, from a specified distribution. We then consider the `consistency graph` arising from
the resulting image triplet (*I*, *I*<sup>'</sup>, *J*). By carefully anlyzing their properties, we propose an unsupervised loss
based on predicting the flow W by the composiiton *I*sup>'</sup> > *J* > *I* via image *J*.

We perform comprehensibe empirical analysis of the objectives derived from our warp consistency grapn and compare them to existing
unsupervised alternatives.

## Method

### 3.1 Problem formulation and notation

We denote flow field to *F*<sub>*I > J*</sub> ∈ R<sup>h * w * 2</sup>, and it is directly related to the mapping *M*<sub>*I > J*</sub>
∈ R<sup>h * w * 2</sup>, which encodes the absolute location in *J* corresponding to the pixel location in image *I*.

It is thus related to the flow through *M*<sub>*I > J*</sub>(*x*) = *x* + *F*<sub>*I > J*</sub>.

Also, We define the warping ø<sub>*F*</sub>(*T*) of a functino *T* : R<sup>2</sup> > R<sup>d</sup> by the flow
*F* as ø<sub>*F*</sub>(*T*)(*x*) = *T*(*x* + *F*(*x*)). This is more compactly expressed as ø<sub>*F*</sub>(*T*) = *T* • *M*<sub>*F*</sub>,
where • denotes function composition.

The goal of this work is to learn a neural network *f*<sub>θ</sub>, with parameters θ, that predicts an estimated flow *F*<sup>^</sup><sub>*I > J*</sub>
= *f*<sub>θ</sub>(*I, J*) relating *I* to *J*.

### 3.2 Unsupervised data losses

#### Photometric losses

#### Forward-backward consistency

#### Warp-supervision













