# Learning Continuous Image Representation with Local Implicit Image Function

## Abstract

In this papaer, we seek to learn a continuous representation for images.

Inspired by the recent progress in 3D reconstruction with implicit neural representation, we prepose LIIF,
which takes an `image cooridnate and the 2D deep features` around the coordinate as inputs, predict the `RGB value` at a given
coordinate as an output.

Since the coordinates are continuous, LIIF can be presented in arbitrary resolution.

## Introduction

While the pixel-based representation has been succesfully applied in various computer vision tasks, they are also constrained
by the resolution.

If we want to train a CNN, we will usually need to resize the images to the same size, which may sacrifice fidelity.
Instead of representing an image with a `fixed resolution`, we propose to study a `continuous representation for images.`
By modeling an image as a function defined in a continuous domain, we can restore and generate the image in `arbitrary resolution`
if needed.

In this paper, we propose the LIIF for representing natural and complex images in a continuous manner.
In LIIF, an image is represented as a `set of latent codes distributed in spatial dimensions.`

We train an encoder with the LIIF representation via a `self-supervised task with super-resolution`, where the
input and ground-truth are provided in continuously changing up sampling scales.

We further demonstrate that LIIF builds a bridge between discrete and continuous representation in 2D.

Our contributions include:
* A novel method for representing natural and complex images continuously
* LIIF representation allows extrapolation to even `30 higher resolution` which is not presented during training time.
* We show LIIF representation is effective for the learning tasks with `size-varied image ground-truths.`

