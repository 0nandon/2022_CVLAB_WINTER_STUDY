# Exploring Simple Siamese Representation Learning

[paper link here](https://papers.nips.cc/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf)

## Abstract

In this papaer, We report that siamese `simple Siamese networks can learn meaningful representations` even using none of the following.
* negative sample pairs
* large batches
* momentum encoders

Our experiments show that collapsing solutions do exist for the loss and structure, but a `stop gradient operation plays an essential
role` in preventing collapsing.

## Introduction

An undesird trivial solution to Siamese networks is all outputs 'collapsing' to a constant. There have been several
general strategies for preventing Siamese networks form collapsing.
* In `SimCLR`, repulses different images while attracting the same image's two views.
* Clustering is another way of avoiding constant output (SWAV)
* `BYOL` relies only on positive pairs but it does not collapse in case a momentum encoder is used.

In this paper, we report that simple Siamese networks can work surprisingly well with none of the above
strategies for preventing collapsing.




