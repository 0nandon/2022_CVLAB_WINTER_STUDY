
# StyleNeRF : A Style-Based 3D-Aware Generator For High-Resolution Image Synthesis

[paper link here](https://arxiv.org/pdf/2110.08985.pdf)

## Abstract

Existing approaches either cannot synthesize `high resolution images` with fine details or yield `noticeable 3D-inconsistent
artifacts.`

StyleNeRF integrates the neural radiance filed (NeRF) into a style-based generator to tackle the aforementioned challenges,
improving `rendering efficiency` and `3D consistency for high-resolution image generation.`

There are two design methods:
* We perform volume rendering only to produce a `low-resolution feature map` and `progressively apply upsampling in 2D`
to address the first issue.
* To mitigate the `inconsistencies caused by 2D upsampling`, we propose multiple desings, including a `better up-sampler`
and a new reqularization loss.

## Introduction

Most GAN models operate in 2D space. Therefore, they lack the `3D understanding of the training images`,
which results in their inability to synthesize images of the same 3D scene with multi-view consistency.

Hence, recent works on generative models enforce 3D structures by incorporating a neural radiance field.
However, these methods `cannot synthesize high-resolution images with delicate details` due to the `computationally
expensive rendering process of NeRF.`

We propose StyleNeRF, a new 3D-aware generative model for `high-resolution 3D consistent image synthesis` at interactive rates.

## Method

### 3.1 Image Synthesis as Neural Implcit Field Rendering

#### Style-based Generative Neural Radiance Field

We start by modeling a 3D scene as neural radiance field. It is typically parameterized as MLP, which
takes *x* ∈ R<sup>3</sup> and viewing direction *d* ∈ S<sup>2</sup> as input, and predicts the density
σ(*x*) ∈ R<sup>+</sup> and view-dependent color *c*(*x, d*) ∈ R<sup>3</sup>. To model high-frequency details,
We use positional encoding (Fourier features):

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_1.png" width=500>

We formalize StyleNeRF representations by conditioning NeRF with style vectors *w* as follows:

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_2.png" width=800>

#### Volume Rendering

Image synthesis is modeled as volume rendering from a given camera pose *p* ∈ P.
We sample the camera's pitch & yaw from a uniform or Gaussian distribution depending on the dataset.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_3.png" width=700>

#### Challenges











