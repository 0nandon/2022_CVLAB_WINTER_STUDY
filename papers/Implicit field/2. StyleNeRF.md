
# StyleNeRF : A Style-Based 3D-Aware Generator For High-Resolution Image Synthesis

[paper link here](https://arxiv.org/pdf/2110.08985.pdf)

## Abstract

Existing approaches either cannot synthesize `high resolution images` with fine details or yield `noticeable 3D-inconsistent
artifacts.`

StyleNeRF integrates the neural radiance filed (NeRF) into a style-based generator to tackle the aforementioned challenges,
improving `rendering efficiency` and `3D consistency for high-resolution image generation.`

There are two design methods:
* We perform volume rendering only to produce a `low-resolution feature map` and `progressively apply upsampling in 2D`
to address the first issue.
* To mitigate the `inconsistencies caused by 2D upsampling`, we propose multiple desings, including a `better up-sampler`
and a new reqularization loss.

## Introduction

Most GAN models operate in 2D space. Therefore, they lack the `3D understanding of the training images`,
which results in their inability to synthesize images of the same 3D scene with multi-view consistency.

Hence, recent works on generative models enforce 3D structures by incorporating a neural radiance field.
However, these methods `cannot synthesize high-resolution images with delicate details` due to the `computationally
expensive rendering process of NeRF.`

We propose StyleNeRF, a new 3D-aware generative model for `high-resolution 3D consistent image synthesis` at interactive rates.

## Method

### 3.1 Image Synthesis as Neural Implcit Field Rendering

We start by modeling a 3D scene as neural radiance field. It is typically parameterized as MLP, which
takes *x*  



