
# StyleNeRF : A Style-Based 3D-Aware Generator For High-Resolution Image Synthesis

[paper link here](https://arxiv.org/pdf/2110.08985.pdf)

## Abstract

Existing approaches either cannot synthesize `high resolution images` with fine details or yield `noticeable 3D-inconsistent
artifacts.`

StyleNeRF integrates the neural radiance filed (NeRF) into a style-based generator to tackle the aforementioned challenges,
improving `rendering efficiency` and `3D consistency for high-resolution image generation.`

There are two design methods:
* We perform volume rendering only to produce a `low-resolution feature map` and `progressively apply upsampling in 2D`
to address the first issue.
* To mitigate the `inconsistencies caused by 2D upsampling`, we propose multiple desings, including a `better up-sampler`
and a new reqularization loss.

## Introduction

Most GAN models operate in 2D space. Therefore, they lack the `3D understanding of the training images`,
which results in their inability to synthesize images of the same 3D scene with multi-view consistency.

Hence, recent works on generative models enforce 3D structures by incorporating a neural radiance field.
However, these methods `cannot synthesize high-resolution images with delicate details` due to the `computationally
expensive rendering process of NeRF.`

We propose StyleNeRF, a new 3D-aware generative model for `high-resolution 3D consistent image synthesis` at interactive rates.

## Method

### 3.1 Image Synthesis as Neural Implcit Field Rendering

#### Style-based Generative Neural Radiance Field

We start by modeling a 3D scene as neural radiance field. It is typically parameterized as MLP, which
takes *x* ∈ R<sup>3</sup> and viewing direction *d* ∈ S<sup>2</sup> as input, and predicts the density
σ(*x*) ∈ R<sup>+</sup> and view-dependent color *c*(*x, d*) ∈ R<sup>3</sup>. To model high-frequency details,
We use positional encoding (Fourier features):

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_1.png" width=500>

We formalize StyleNeRF representations by conditioning NeRF with style vectors *w* as follows:

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_2.png" width=800>

#### Volume Rendering

Image synthesis is modeled as volume rendering from a given camera pose *p* ∈ P.
We sample the camera's pitch & yaw from a uniform or Gaussian distribution depending on the dataset.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_3.png" width=700>

#### Challenges

However, the drawbacks are apparent:
* these models `cost much more computation` to render an image at the exact resolution.
* Furthermore, NeRF `consumes much more memory` to cache the intermediate results for gradient back-propagation
during training, making it difficult to train on high-resolution images.

### 3.2 Approximation for High-resolution Image Generation

We observe that the image generation of 2D GANs is fast due to two main reasons:
* each pixel only takes single forward pass through the network
* image features are generated progressively from `coarse to fine`, and the feature maps with higher resolutions typically
have a `smaller number of channels` to save memory.

In StyleNeRF, the first point can be partially achieved by `early aggregation` the features into the 2D space before
the final colors are computed.

Furthermore, it only needs to pass through a network once rather than calling the network multiple times for all sampled
points on the ray as NeRF does.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_4.png" width=800>

Next, instead of using volume rendering to render a high-resolution feature map directly, we can employ NeRF to generate
a downsampled feature map at a low resolution and then employ `upsampling in 2D space` to progressively increase into
the required high resolution.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_5.png" width=400>

While early aggregation and upsampling operations can accelerate the rendering process for high resolution image synthesis,
they would come with `scarification to the inherent consistency of NeRF.`

### 3.3 Preserving 3D Consistency

#### [Upsampler design]

Up-sampling in 2D space causes multi-view inconsistency in general; however, the specific design choice
of the upsampler determines `how much such inconsistency is introduced.`

#### [NeRF path regularization]

We propose a new reqularization term to enforce 3D consistency, which reqularizes the model output to match
the original path. In this way, the final outputs can be closer to the NeRF results, which have `multi-view consistency.`

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_6.png" width=600>

### 3.4 StyleNeRF Architecture

In this section, we describe the network architecture and the learning procedure of StyleNeRF.

<img src="https://github.com/0nandon/2022_CVLAB_WINTER_STUDY/blob/main/photo/StyleNeRF_8.png" width=700>

#### [Mapping Network]

Following StyleGAN2, latent codes are sampled from standard Gaussian and processed by a mapping network.
Finally, the output vectors are broadcast to the synthesis networks.

#### [Synthesis Network]

Two MLPs are used to predict the density where the background network has fewer parameters than the foreground one.
Then a shared MLP is employed for color prediction. 

Each style-conditioned block consists of an affine transformation layer and a 1 * 1 convolution layer.

#### [Discriminator & Objectives]

We use the same discriminator as StyleGAN2. A new NeRF path regularization is employed to enfore 3D consistency.

#### [Progressive training]

We train StyleNeRF progressively from `low to high resolution`, which makes the training more stable and efficient.

## Limitation and Future work

* It scarifices come properties that pure NeRF-based methods have.
* It captures less details compared to the pure NeRF-based models sucn as π-GAN.
* It does not gurantee strict 3D-consistency.

## Conclusion

We proposed a 3D aware generative model, StyleNeRF, for efficient high-resolution image generation with
high 3D consistency, which allows control over explicit 3D camera poses and style attributes.
